var documenterSearchIndex = {"docs":
[{"location":"#IterativeNelderMead.jl","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.jl","text":"","category":"section"},{"location":"","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.jl","text":"Documentation for IterativeNelderMead.jl","category":"page"},{"location":"#Details","page":"IterativeNelderMead.jl","title":"Details","text":"","category":"section"},{"location":"","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.jl","text":"This flavor of Nelder-Mead is based on the publicly available Matlab algorithm provided here with additional tweaks. It is an excellent choice for derivative-free objectives. Parameters can be passed via usual Julia vectors or a simple Dictionary-like API. Support for parameter bounds is provided, but any constraints must be manually implemented through the objective function. The goal for IterativeNelderMead.jl is for support through the SciML Optimization.jl interface.","category":"page"},{"location":"#Examples","page":"IterativeNelderMead.jl","title":"Examples","text":"","category":"section"},{"location":"#Example-1:-Curve-fitting-with-vectors-API","page":"IterativeNelderMead.jl","title":"Example 1: Curve fitting with vectors API","text":"","category":"section"},{"location":"","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.jl","text":"# Imports\nusing IterativeNelderMead\nusing PyPlot\n\n# Build a Gaussian function\nfunction gauss(x, a, μ, σ)\n    return @. a * exp(-0.5 * ((x - μ) / σ)^2)\nend\n\n# Create a noisy toy dataset\nx = [-20:0.05:20;]\nptrue = [4.0, 1.2, 2.8]\nytrue = gauss(x, ptrue...)\nyerr = abs.(0.1 .+ 0.1 .* randn(size(ytrue)))\nytrue .+= yerr .* randn(size(ytrue))\n\n# Chi2 loss function\nredχ2loss(residuals, yerr, ν) = sum((residuals ./ yerr).^2) / ν\nloss(pars) = redχ2loss(ytrue .- gauss(x, pars...), yerr, length(ytrue) .- length(pars))\n\n# Initial parameters and model\np0 = [3.0, -4.2, -4.1]\nlower_bounds = [0, -Inf, 0]\nupper_bounds = [Inf, Inf, Inf]\ny0 = gauss(x, p0...)\n\n# Optimize\nresult = optimize(loss, p0, IterativeNelderMeadOptimizer())\n\n# Best fit model\nybest = gauss(x, result.pbest...)\n\n# Plot\nbegin\n    errorbar(x, ytrue, yerr=yerr, marker=\"o\", lw=0, elinewidth=1, label=\"Data\", zorder=0)\n    plot(x, y0, c=\"black\", label=\"Initial model\", alpha=0.6)\n    plot(x, ybest, c=\"red\", label=\"Best fit model\")\n    legend()\n    plt.show()\nend","category":"page"},{"location":"#Example-2:-Curve-fitting-with-Parameters-API","page":"IterativeNelderMead.jl","title":"Example 2: Curve fitting with Parameters API","text":"","category":"section"},{"location":"","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.jl","text":"# Imports\nusing IterativeNelderMead\nusing PyPlot\n\n# Build a Gaussian function \nfunction gauss(x, pars)\n    a = pars[\"a\"].value\n    μ = pars[\"μ\"].value\n    σ = pars[\"σ\"].value\n    return @. a * exp(-0.5 * ((x - μ) / σ)^2)\nend\n\n# Create a noisy toy dataset\nx = [-20:0.05:20;]\nptrue = Parameters()\nptrue[\"a\"] = Parameter(value=4.0)\nptrue[\"μ\"] = Parameter(value=1.2)\nptrue[\"σ\"] = Parameter(value=2.8)\nytrue = gauss(x, ptrue)\nyerr = abs.(0.1 .+ 0.1 .* randn(size(ytrue)))\nytrue .+= yerr .* randn(size(ytrue))\n\n# Chi2 loss function\nredχ2loss(residuals, yerr, ν) = sum((residuals ./ yerr).^2) / ν\nloss(pars) = redχ2loss(ytrue .- gauss(x, pars), yerr, length(ytrue) .- length(pars))\n\n# Initial parameters and model\np0 = Parameters()\np0[\"a\"] = Parameter(value=3.0, lower_bound=0, upper_bound=Inf)\np0[\"μ\"] = Parameter(value=-4.2)\np0[\"σ\"] = Parameter(value=4.1, lower_bound=0, upper_bound=Inf)\ny0 = gauss(x, p0)\n\nresult = optimize(loss, p0, IterativeNelderMeadOptimizer())\nybest = gauss(x, result.pbest)\n\nbegin\n    errorbar(x, ytrue, yerr=yerr, marker=\"o\", lw=0, elinewidth=1, label=\"Data\", zorder=0)\n    plot(x, y0, c=\"black\", label=\"Initial model\", alpha=0.6)\n    plot(x, ybest, c=\"red\", label=\"Best fit model\")\n    legend()\n    plt.show()\nend","category":"page"},{"location":"","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.jl","text":"The resulting plot is shown below.","category":"page"},{"location":"","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.jl","text":"(Image: Curve fitting plot)","category":"page"},{"location":"#API","page":"IterativeNelderMead.jl","title":"API","text":"","category":"section"},{"location":"","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.jl","text":"IterativeNelderMeadOptimizer","category":"page"},{"location":"#IterativeNelderMead.IterativeNelderMeadOptimizer","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.IterativeNelderMeadOptimizer","text":"IterativeNelderMeadOptimizer(;options=nothing)\n\nConstruct an IterativeNelderMeadOptimizer optimizer. options is of type Dict{String, Any}. Default options are:\n\nmax_fcalls = 1400 * number of varied parameters. The number of objective calls is not reset after each iteration / subspace.\nno_improve_break = 3. For a given parameter space, the number of times the solver needs to converge in a row to officially be considered converged. This applies to all parameter spaces / iterations.\nftol_rel = 1E-6. For a given parameter space, the relative change in the objective function to be considered converged. This applies to all parameter spaces / iterations.\nn_iterations = number of varied parameters.\n\n\n\n\n\n","category":"type"},{"location":"","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.jl","text":"optimize","category":"page"},{"location":"#IterativeNelderMead.optimize","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.optimize","text":"optimize(obj, p0::Vector{<:Real}, optimizer::IterativeNelderMeadOptimizer, [lower_bounds, upper_bounds, vary])\noptimize(obj, p0::Parameters, optimizer::IterativeNelderMeadOptimizer)\n\nMinimize the object function obj with initial parameters p0 using the IterativeNelderMeadOptimizer solver. Lower bounds can also be provided as additional vectors or using the Parameter API. Returns an NamedTuple with properties:\n\npbest::Parameters or Vector, the parameters corresponding to the optimized objective value fbest.\nfbest::Float64, the optimized objective value.\nfcalls::Int, the number of objective calls.\n\n\n\n\n\n","category":"function"},{"location":"","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.jl","text":"Parameter\nParameters","category":"page"},{"location":"#IterativeNelderMead.Parameter","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.Parameter","text":"Parameter(;name=nothing, value::Real, lower_bound::Real=-Inf, upper_bound::Real=Inf, vary::Bool=true, latex_str=nothing)\n\nConstruct a new parameter. The parameter name does not have to be provided and will be automatically set if using the dictionary interface.\n\n\n\n\n\n","category":"type"},{"location":"#IterativeNelderMead.Parameters","page":"IterativeNelderMead.jl","title":"IterativeNelderMead.Parameters","text":"Parameters()\n\nConstruct an empty Parameters struct.\n\n\n\n\n\nParameters(x::AbstractVector{<:Real}, names::AbstractVector{<:AbstractString}, lower_bounds=nothing, upper_bounds=nothing, vary=nothing)\n\nConstructor from vectors.\n\n\n\n\n\n","category":"type"}]
}
